# ğŸš— BEV Segmentation Pipeline â€” Complete Implementation

A production-ready Bird's Eye View (BEV) perception system for autonomous driving, featuring multi-view camera fusion and semantic segmentation.

<table>
<tr>
<td><img src="examples/5.png" alt="BEV Segmentation Example 1" width="400"/></td>
<td><img src="examples/4.png" alt="BEV Segmentation Example 2" width="400"/></td>
</tr>
</table>   

## ğŸ“‚ Dataset

We use the **Kaggle Semantic Segmentation BEV Dataset**:

* **Training samples:** 33,199
* **Validation samples:** 3,731
* **Cameras:** Front, Rear, Left, Right (RGB, 384Ã—384)
* **Labels:** BEV semantic maps (7 classes)
* **Classes:** 0:unlabeled, 1:car, 2:vegetation, 3:road, 4:terrain, 5:guard_rail, 6:sidewalk
* **Calibration provided:**
  * Intrinsics â†’ focal length (fx, fy), principal point (cx, cy)
  * Extrinsics â†’ position (x,y,z), rotation (yaw, pitch, roll)

---

## ğŸ—ï¸ Architecture

### **Pipeline Flow:**
```
Single Timestep Mode:
Camera Images (B, 3, 384, 384) Ã— 4 views
    â†“ [Backbone - ResNet50]
Features (B, 64, 12, 12) Ã— 4 views  
    â†“ [View Transform]
BEV Features (B, 64, 256, 256)
    â†“ [BEV Encoder] 
Encoded Features (B, 128, 64, 64)
    â†“ [Decoder]
Segmentation (B, 7, 256, 256)
    â†“ [Loss]
Ground Truth (B, 256, 256)

Temporal Fusion Mode:
t=-2: [4 cameras] â†’ Backbone â†’ Features â”
t=-1: [4 cameras] â†’ Backbone â†’ Features â”œâ†’ Temporal Fusion â†’ BEV Transform â†’ BEV Encoder â†’ Decoder â†’ BEV Segmentation
t=0:  [4 cameras] â†’ Backbone â†’ Features â”˜
```

## ğŸš€ Quick Start

### Prerequisites
```bash
# Activate conda environment
conda activate bev

# Install dependencies
pip install -r requirements.txt
```

### Component Details
For detailed information about each module, see [src/src.md](src/src.md).


### Training Pipeline
```bash
# Start training with real data
python train_pipeline.py

# Use different configurations (all in single config.yaml)
python train_pipeline.py --config configs/config.yaml
```

---

## ğŸš€ Complete Pipeline Overview

### **âœ… Fully Implemented & Tested**
A production-ready BEV segmentation pipeline with:

**ğŸ§  Core Architecture:**
- **Multi-View Fusion**: 4 cameras (Front, Left, Rear, Right) â†’ ResNet50/18 backbone
- **View Transform**: Adaptive pooling placeholder (not true LSS) for BEV projection
- **BEV Processing**: CNN encoder-decoder for 7-class segmentation
- **Temporal Fusion**: Optional multi-timestep processing (3 frames)

**ğŸ“Š Performance Specs:**
- **Model**: 94.4 MB (24.7M parameters, 1.2M trainable)
- **Resolution**: 224Ã—224 cameras â†’ 224Ã—224 BEV (configurable)
- **Classes**: 7 classes optimized for trajectory planning
- **Memory**: ~2-4 GB GPU (RTX 3060)
- **Speed**: ~0.5-1.0 seconds per batch

**ğŸ¯ Key Features:**
- **Class Balance**: Focal Loss handles severe imbalance (road:terrain ~1:1)
- **Training**: Mixed precision, gradient clipping, comprehensive metrics
- **Management**: Runs organization, checkpoints, Weights & Biases integration
- **Utilities**: Class weight calculation, model evaluation, visualization
---

## ğŸ“ Project Structure

```
BEV_segmentation/
â”œâ”€â”€ src/                     # Core source code (see src/src.md for details)
â”œâ”€â”€ configs/config.yaml      # Single consolidated configuration
â”œâ”€â”€ tests/                   # Test files
â”œâ”€â”€ runs/                    # Experiment results
â”œâ”€â”€ data/                    # Dataset (33,199 train + 3,731 val)
â”œâ”€â”€ examples/                # Sample visualizations and results
â”œâ”€â”€ train_pipeline.py        # Main training script
â””â”€â”€ requirements.txt         # Dependencies
```

## ğŸ–¼ï¸ Example Results

The `examples/` folder contains sample visualizations from the BEV segmentation pipeline:

### Sample BEV Segmentation Result

![BEV Segmentation Example](examples/2.png)

*Example showing multi-view camera fusion (Front, Left, Rear, Right) and resulting BEV semantic segmentation with 7 classes*

### Additional Examples

- **`2.png`** - Sample with different road conditions and vehicle detection
- **`3.png`** - Complex scenario with multiple classes and temporal fusion

These examples demonstrate the pipeline's ability to:
- Fuse information from 4 camera views (Front, Left, Rear, Right)
- Generate accurate BEV semantic segmentation
- Handle various driving scenarios and road conditions

## ğŸ§ª Testing

### **Individual Component Tests**
```bash
# Test each component
python -m src.backbone       # ResNet50 feature extraction
python -m src.bev_encoder    # BEV feature processing
python -m src.decoder        # Segmentation head
python -m src.view_transform # Multi-view projection
python -m src.temporal_fusion # Temporal fusion module
python -m src.model          # Complete model
python -m src.dataset        # Dataset loading
```

### **Complete Pipeline Test**
```bash
# Test entire pipeline
python train_pipeline.py

# Test temporal fusion integration
python tests/test_temporal_fusion.py

# 2. Train the model
python train_pipeline.py --config configs/config.yaml
```

### **Evaluation and Utilities**
```bash
# Calculate class weights (recommended before training)
python -m src.calculate_class_weights --config configs/config.yaml --num-samples 20

# Evaluate trained model (find checkpoint in runs/ directory)
python -m src.evaluate_model --checkpoint runs/run_TIMESTAMP/checkpoints/best_model.pth --num-samples 20

# Or evaluate specific checkpoint
python -m src.evaluate_model --checkpoint runs/run_TIMESTAMP/checkpoints/best_model.pth --num-samples 20
```

## ğŸ”§ Configuration

All settings in `configs/config.yaml` with inline comments for different modes:
- **Resolution**: 224Ã—224 (Fast) | 256Ã—256 (Balanced) | 384Ã—384 (High-res)
- **Backbone**: ResNet18 (Fast) | ResNet50 (High-res)
- **Data**: 25% (Fast) | 50% (High-res) | 100% (Full)
- **Temporal**: Disabled (Fast) | Enabled (High-res)

## ğŸ”® Future Enhancements

* **Advanced LSS**: Proper Lift-Splat-Shoot implementation
* **Performance Optimization**: Memory and speed improvements
* **Real-time Inference**: Optimization for deployment